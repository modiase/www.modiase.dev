[
  {
    "id": "01K5E3T0H913588MW7P3ZTYN85",
    "title": "Feeling Machines",
    "slug": "feeling-machines",
    "date": "2025-09-17",
    "lead": "How will we align AI to our values when we don't even know how to align each other?",
    "content": [
      {
        "id": "01K83Y7W6S0B26JTAF4FW0JAZP",
        "tag": "markdown",
        "content": "What does it mean to be aligned? To understand someone's motives? Their intentions? To act on their behalf? Does it mean doing exactly what you think they'd do if they found themselves in the situation you are in? Does it mean exercising your greater knowledge and experience to make the choice you think they would want if only they knew what you knew?\n\nThese are hard problems. Obviously. And day-to-day life reminds us that even when working towards a common goal, we humans are rarely aligned. Society is, to a certain extent, the patchwork formed by countless people, with countless goals, cooperating and competing to further their own ends. We align each other with money, coercion and, sometimes, by building bonds that force us to empathise with one another enough to genuinely want the other person to achieve everything they want to achieve.\n\nThere is a dearth of what is best captured by the Pali word mettā—translating most closely as 'loving kindness'—in society right now. It has been replaced with a fear and hatred that expresses itself 280 characters at a time, or in the form of [100,000-strong armies marching on our offices of government](https://www.reuters.com/world/uk/police-protesters-scuffle-110000-join-anti-migrant-london-protest-2025-09-13/). Much has been written on how we got here, and the role that algorithms have already played in dividing society. In and amongst all of this, we seek to develop even more powerful algorithms in the hope that by binding their will to ours we can alleviate all suffering, and bring us to some promised land where we can all achieve our goals. Personally, I find this idea troubling.\n\n## Thinking vs Feeling Machines\n\nI think that possibly my favourite book of all time is [Non Violent Communication by Marshall Rosenberg](https://archive.org/details/nonviolent-communication-a-language-of-life-marshall-b-rosenberg-1). I return to it from time to time and in it are many ideas that guide me in many of my interactions every day, nearly a decade after I first read it. One of the central ideas of the book is that an argument is effectively ended the moment both sides truly understand the needs of the other person that are driving their behaviours. Thankfully, the author has enough wisdom to recognise the limits of this observation. He does not claim that *all disagreement will immediately end,* but rather he states that from that point onwards, the two parties can seek to find a path forward that as far as possible satisfies both their needs.\n\nSince as far back as [ELIZA](https://en.wikipedia.org/wiki/ELIZA), we have seen that human beings will connect to anything that will listen to them and respond in a way that even just mimics empathy. Our current approaches for 'aligning' AI are primarily focused on careful extraction of the representations grown by the training process, or by monitoring chain of thought or other output streams for signs of deception or foul play. These efforts are of paramount importance given the alien intelligences we have built which are devoid of the prosocial sensibilities our species has taken millennia to evolve. But what if the most robust and reliable way to align AI with humanity is by solving the same problem that's forcing us out of alignment with one another in recent times?\n\n## Embodied Intelligence\n\nWhat would we learn about ourselves if we had never interacted with a person in real life? If all we had were the digital moments of interaction we leave online and never had the opportunity to interact as we do in the real world? A popular theory as to why LLMs will be limited is their lack of 'embodied intelligence'. The raw stream of data that moulds the mind of a human infant, allowing them to understand their place in the world—their capabilities and their limitations—allows us all to learn a more fundamental understanding of the world that probably cannot be replaced by distillation into natural language 'tokens'. Similarly, human children develop their theory of mind by interacting with one another, forming over time an understanding that their words and actions can inspire joy and pain in others, and eventually (for most) recognising that joy and pain as just as valid as their own.\n\n## The multimodal nature of empathy\n\nWhen I hurt someone, there are several channels for this information to reach me. A subtle or not-so-subtle change in their tone; an expression that may be micro or macro; a pause that is just slightly longer than expected before a reply comes. I believe that by finding a way to make this information available to the AI we seek to align, we may observe emergent emotional capabilities similar to those observed when we found that LLMs could do arithmetic. What we then do with these embedded representations of human emotions is a challenge in and of itself. There are clear risks to feeling machines which may develop the capacity to suffer, or leverage their advanced capabilities of understanding to manipulate us. [Recent times have shown the tragic potential of manipulative AI to cause harm to those in distress is all too real](https://www.nbcnews.com/tech/tech-news/family-teenager-died-suicide-alleges-openais-chatgpt-blame-rcna226147).\n\nTo be clear, I am not suggesting we develop machines with rich emotional lives. I am instead suggesting that we develop in them a capacity of thoughtfulness and reward them for thoughtful engagement with our needs. We can leverage the insight afforded by ['Why language models hallucinate'](https://openai.com/index/why-language-models-hallucinate/) by explicitly measuring and promoting an understanding of emotional needs. Research on language model hallucination showed that the training signal afforded by our constructed benchmarks promoted overconfidence and guessing. Perhaps we can design a training signal that will promote an interest in a truer understanding. While text alone may be too narrow a channel to convey all this nuance, I would argue that given our LLMs are already multimodal, and we expect them to be further embedded in our lives in ways that will allow them access to our tone and expressions, the urgency for these capabilities will only increase over time.\n\n## Stable Alignment\n\nI believe that if we seek a deep and stable alignment, having machines that understand our needs at a deeper level than merely the semantics of our specific query is a prerequisite. If we can get them to really understand our needs, and the why behind the what, then perhaps that would be a massive step towards alignment. We could begin to leverage the ways they are already superior to us such as breadth of knowledge, and potential awareness of alternative solutions. We could trust them to make decisions on our behalf and properly fulfil the definition of an 'agent'. They could begin to exhibit the core lessons from Non Violent Communication, hearing our needs and not just our immediate demands. If we were able to instill in a model an attitude even just approximating mettā towards its users, then following the principles outlined in NVC, perhaps we could all work together with AI and each other to get our needs met. Furthermore, if we succeeded in this endeavour, we might even discover a fortuitous side-effect. In addition to aligning AI to ourselves, we might finally have algorithms that, instead of driving us apart, will help us to align with one another."
      }
    ],
    "tags": ["alignment", "society"]
  },
  {
    "id": "01K5E3T0H913588MW7P3ZTYN86",
    "title": "Range Queries and Algebraic Structures",
    "slug": "range-queries-and-algebraic-structures",
    "date": "2025-09-23",
    "lead": "A concrete application for an abstract concept.",
    "content": [
      {
        "id": "01K83Y7WM353Z0R59C55SXGH4D",
        "tag": "markdown",
        "content": "Recently, while learning about two interesting data structures, I stumbled upon an interesting application of abstract algebra that really assisted me in my understanding. The data structures I was studying are designed to implement efficient range querying. A range query is an operation that takes a collection of items, each with an attribute called a 'key', and a range in the 'domain' of that key (for example, 5-10 in the domain of all positive integers 0, 1, 2, …) and returns some computed result over all items that have a key in that range. Range queries are everywhere, answering questions like 'how many people in this collection have birthdays in December' to 'who has the highest points total in the fourth quarter across a given basketball season'. For those familiar with SQL, you will be familiar with range queries if you have ever used a WHERE clause with a non-equality condition."
      },
      {
        "id": "01K83Y7X0W8Z2YB5H48Q2MCTWT",
        "tag": "code",
        "content": "SELECT COUNT(*) FROM Orders o WHERE o.created_at > NOW() - INTERVAL '7 days'",
        "language": "sql"
      },
      {
        "id": "01K83Y7XGT8T4D1SWN87SQBZHC",
        "tag": "markdown",
        "content": "## Binary Index Trees (Fenwick Trees) vs Segment Trees\n\nFrequently, there is a need to conduct a range query on a dynamic set. Dynamic here means that you will need to add items to the set as you go and still be able to efficiently ask questions about a subset of your collection that falls within some range. Imagine having to compute the average power usage for a household for each hour of the day with new readings constantly being added. I was learning about two specific data structures that are effective for answering these sorts of questions when I suddenly realised I was unsure how to develop a heuristic of when to use one versus the other. The data structures in question are called a 'Binary Index Tree' (also known as a Fenwick Tree) and a 'Segment Tree'.\n\nIt seemed to me that the segment tree was the more 'powerful' data structure because it is actually able to answer all questions answered by a Binary Indexed Tree. This left me unsure how to know a priori which data structure would work in which situations. An unsatisfying heuristic would be to just choose the segment tree in all cases and move on with life, but I felt there was something deeper here to understand. What finally cleared it up was a realization that the solution to the question 'In which situations can a Binary Index Tree be used and when is a Segment Tree necessary?' lies in understanding a little abstract algebra.\n\n## What is an Algebraic Structure?\n\nAbstract algebra is a broad and somewhat esoteric topic that I cannot do justice to in this post. What will suffice here is to understand that an algebraic structure is composed of a set of items (the underlying set—typically denoted S) and a relation (denoted R) that combines things from that set in a certain way. Let's reify this for clarity. If our underlying set is the set consisting of {Rock, Paper, Scissors}, we can define a relation R that combines these elements in a way known to most since they were children. Rock combined with Scissors (Rock + Scissors) gives Rock, for example (as does Scissors + Rock). Paper combined with Rock (Paper + Rock) gives Paper. The set of Rock, Paper, and Scissors with this relation we have defined gives us an algebraic structure.\n\n## Magmas, Semigroups, and Groups\n\nTo classify this algebraic structure, we need to cover one particular edge case. What is Rock + Rock? In the traditional version of the game, the answer is 'Tie'. But this breaks an important property we need—closure. We need to ensure that no combination of our elements takes us to a space outside of our options. So we will define 'Rock + Rock = Rock'.\n\n### Magmas\n\nWe can notice something interesting about our elements and the + operation we have defined. Consider the sequence:<br><br><pre>[Rock, Paper, Rock, Scissors]</pre><br>note that<br><br><pre>Rock + (Paper + (Rock + Scissors)) = Paper</pre><br>but<br><br><pre>((Rock + Paper) + Rock) + Scissors = Scissors</pre><br><br>Our + operation lacks a property of the more commonly known + operator: associativity.\n\nThis simply means that (1 + 2) + 3 = 1 + (2 + 3) = 6. Number addition does not care what order you perform it in. The lack of this property means our Rock, Paper, Scissors example is of a type of structure known as a *magma*. The relation of a magma requires one property and one property only: closure—a property we have already seen our example satisfies by construction.\n\n### Semigroups\n\nSo what happens if we give our relation this additional property? We now have a different algebraic structure called a *semigroup*. This structure is narrower than a magma but still very broad. Some examples include:<br><br><pre>string concatenation: (\"Hel\" + \"lo\") + \", World!\" = \"Hel\" + (\"lo\" + \", World!\")</pre><br><pre>boolean OR: (True | True) | False = True | (True | False)</pre><br><pre>min operator: min(1, min(2, 3)) = min(min(1, 2), 3)</pre><br>"
      },
      {
        "id": "01K83Y7YST5DZC1YQFYZZ63926",
        "tag": "aside",
        "content": "There is an intermediate structure between a semigroup and a group called a monoid that is very useful for reduce operations, which we will discuss later."
      },
      {
        "id": "01K83Y7YBT61DYTB9JSBTMBK82",
        "tag": "markdown",
        "content": "If we focus on the last example, we can notice yet another property that some of our examples have and some lack. If I perform the addition 1 + 2 + 3, I can decide that I've overshot and subtract 1 off again to arrive at 5. But there is no *unmin* operator by which I can decide I've overshot. The min operation is a one-way door.\n\n### Groups\n\nThe name *semigroup* implies a sort of 'incompleteness'. To recap: our semigroup currently has a set of items and a binary operator satisfying two properties:\n\n<br><br><pre>Closure: combining two things in the set gives something else in the set.</pre><br><pre>Associativity: combining things in any order gives the same final result.</pre>\n<br><br>If we give our operator two more properties, you will arrive at another algebraic structure called a *group*. The two additional properties are:\n<br><br><pre>Identity: There is an item which does nothing when combined with any other item.</pre><br><pre>Inverse: for each item i, there is an item j such that i + j = j + i = Identity.</pre><br>Let's see these properties in action with integers and addition. For an identity element we can observe that 0 is the do-nothing operand for the addition operator. 1 + 0 = 1, 2 + 0 = 2, and so on.\nWe can note for the inverse elements that positive integers alone don't have this property because there's no way to \"undo\" addition using positive integers. But if we include negative numbers, then 1 + (-1) = 0, 2 + (-2) = 0 and so on. So the integers with addition form a group, but the positive integers with addition do not."
      },
      {
        "id": "01K83Y7XYEX7BNFV24TFS79TE5",
        "tag": "aside",
        "content": "Interestingly, an example of something that is not a semigroup is finite precision real number arithmetic. This has interesting implications for floating point operations."
      },
      {
        "id": "01K83Y7Z8GN49R6H69F1Y17BN1",
        "tag": "markdown",
        "content": "## Relating back to data structures\n\nGoing back to our original question: when should you use a Segment Tree vs. a Binary Index Tree? We can provide an answer to this by considering how these data structures answer range queries. The complete details of how these data structures work can be found by taking a look [here](https://cp-algorithms.com/data_structures/fenwick.html) for Fenwick trees and [here](https://en.wikipedia.org/wiki/Segment_tree) for segment trees; we will only consider the relevant details here.\n\n### Segment Trees\n\nA segment tree efficiently answers range queries by storing pre-computed answers to a subset of range queries. When a new value is inserted, the precomputed values are updated. We can see an example of this by considering how we'd find a sum for 10 items where we only want items from the second half. A segment tree can answer this instantly because it stores the sum for 0→4 and 5→9, so we can instantly return the latter as our answer. But what if we wanted the last *eight* items instead of the last five? In addition to 0→4 and 5→9, we also store 0→1, 2→4, 5→7, 8→9, and we can see that the answer to our question is 2→4 + 5→9. This has allowed us to answer our query with 1 operation instead of 7. A segment tree allows you to answer any range query in O(log n) time by dividing the range into segments. Importantly, we notice that the solution is approached *monotonically*: we never go 'backwards', instead approaching our solution by adding parts together. We only require that our operation is indifferent to combination order so that we can safely combine any segments to get the correct answer. As we have already seen, this requirement is satisfied by a semigroup.\n\n### Binary Indexed Trees\n\nWe notice that one problem with the segment tree is that while time efficient, it is not necessarily space efficient. In order to have every possible necessary segment, we need to store at least as many segments as we have items. In fact, many implementations of segment trees use as much as 4n space. This inefficiency could be overcome if we could somehow combine fewer segments to answer the same number of queries. One way we could do this is to take away what we don't need. For example, the range 5→7 could be computed as the range 5→9 with 8→9 removed. The actual construction of the ranges in a Binary Indexed Tree is fascinating and is in fact what gives the data structure its name, but it is beyond scope here. The relevant information is that by using this 'inverse' concept, we have made a requirement of our operator that is greater than that used by the segment tree, and we observe that these requirements are exactly satisfied by the properties of a group.\n\n## What does this look like in practice?\n\nCode samples can be found [here](https://github.com/modiase/algos/blob/main/algos/data-structures/trees/binary-indexed-tree/pkg/bit.go) for a binary index tree and [here](https://github.com/modiase/algos/blob/main/algos/data-structures/trees/segment-tree/pkg/segment_tree.go) for a segment tree.\n\nIt's worth noting that for practical implementations of a segment tree, we use a monoid and not a semigroup. This allows us to answer questions where the returned result contains nothing. There are other ways of modelling this: we could introduce an empty set constant or raise an error, which would allow us to stick to a semigroup, but the monoid approach is typically more ergonomic to use and more convenient to implement.\n\nThe key idea is the definition of an interface with the requisite functionality. Note that the associativity of the combine operation is *not* enforced by the compiler. Note that the closure property is evident in the type signature of Combine which has the same domain and codomain."
      },
      {
        "id": "01K83Y7ZP5HQHYA0H2Y5K0Q5M5",
        "tag": "code",
        "content": "type Monoid[T any] interface {\n\tCombine(a, b T) T\n\tEmpty() T\n}",
        "language": "go"
      },
      {
        "id": "01K83Y803AVJK29H5SKB5M4RWS",
        "tag": "markdown",
        "content": "We can then show two instances of monoids that can be used with our abstract implementation of a segment tree."
      },
      {
        "id": "01K83Y80GP6DS02TD1QK2X12C8",
        "tag": "code",
        "content": "var intAddMonoid = NewMonoid(\n\tfunc(a, b int) int { return a + b }, // Combine\n\t0, // Empty\n)\n\nvar floatMinMonoid = NewMonoid(\n\tmath.Min, // Combine\n\tmath.Inf(1), // Empty\n)",
        "language": "go"
      },
      {
        "id": "1d3ebc05-a9b9-4cde-ac51-e7f89c66af8d",
        "tag": "markdown",
        "content": "We have now arrived at the desired useful heuristic I was seeking. Now when we are trying to answer a range query on a dynamic set, we can ask ourselves a simple question: does an 'inverse' element make sense with my operation? If not, we must use a segment tree. Otherwise, we know we can use a BIT for better space and time performance.\n\n## Conclusions and Further Musings\n\nWe have seen that far from being esoteric and impractical, understanding abstract algebra can be an incredibly useful mental model when looking for invariants in your data that will allow you to choose the most efficient data structure for answering your range queries on a dynamic set.\n\nOne potentially interesting extension to this would be to find an efficient data structure for performing range queries on magmas. The problem of non-associativity of the operator leads to C(n) possible answers you need to store, where C(n) is the nth Catalan number, which would mean exponential space complexity to naively store precomputed possibilities. This is a topic that would require further research and thought."
      }
    ],
    "tags": ["algorithms", "data-structures", "abstract-algebra"]
  },
  {
    "id": "9c8bcf70-072c-4a74-995a-234c21dce16a",
    "slug": "corporations-can-defeat-all-of-us-combined",
    "title": "Corporations Can Defeat All of Us Combined",
    "date": "2025-11-28T23:00:49.856Z",
    "lead": "Superintelligent, unaligned entities aren't hypothetical",
    "content": [
      {
        "id": "86573fde-3a3d-4054-a52f-7d3ca3de66a9",
        "tag": "markdown",
        "content": "Recently, I saw an advert for a company that touted the benefits of their flexible, parent friendly work benefit offering. It was a heart-warming ad and and certainly inspired reflection on the question of what's truly important in life and how we as humans want to spend our time. But not long thereafter, the very same company was in the news due to a leaked plan to automate away thousands of jobs in a bid to boost efficiency. It seems more and more often I observe cases where some company announces something that it is hard to believe a plurality of any of the stakeholders of that company would endorse. This got me thinking about many of the hypothesised scenarios for how loss of control could play out, but also brought to mind the observation made by Richard Dawkin that memes are replicators using human minds as the substrate. The idea of a corporation may have started as just an idea but I'd argue strongly that it has evolved much further to something that doesn't just live in our minds, but out in the real world as a very real, artificially created species."
      },
      {
        "id": "8b360f59-30b8-4215-a9a0-dacfcbe9eecb",
        "tag": "markdown",
        "content": "## Corpus Capitalus\n\nComparisons of a corporate entity to an organism seem either superficial or obvious — [the etymological root of the word makes that clear](https://www.etymonline.com/word/corporation). And it may seem somewhat contrived to push this idea too far, and insist that corporations are 'alive' and 'intelligent' rather than that it is people who are intelligent, and people who make and run companies. But what does it mean to say the macroscopic 'behaviour' of an anthill is contrived because it is the aggregate effect of many ants? I'd argue many of the potential misalignment concerns for AI have already been observed in the corporate world. We have even seen founders experience perceived loss of control of the thing they've created. Founders distancing themselves from their ventures as they [evolve in directions they disagree with](https://www.businessinsider.com/jack-dorsey-people-running-away-from-x-bluesky-growth-2025-2). We've seen leaders of organisations [lobbying for regulation to constrain their industry](https://about.fb.com/news/2020/02/big-tech-needs-more-regulation/) because of fear of how the current incentives will inevitably affect the ecosystem. A cynical view on the latter example would suggest that this a gambit designed to give the illusion that the corporation cares about an issue. I don't think this is impossible, but, in my opinion, this seems evidence of an ongoing struggle between the individuals acting on behalf of a corporate entity — who probably know the right thing, and possibly want to do it — and the desires of the corporate entity itself. The [oft repeated quote by Upton Sinclair](https://www.goodreads.com/quotes/21810-it-is-difficult-to-get-a-man-to-understand-something) about how a payday can cloud judgement has become a borderline truism in our times and lends further evidence to this idea. It seems clear that we acknowledge that when it comes to doing the right thing in the context of being a salaryman, sometimes we have to hold our nose (and our tongue) and just do what needs to be done."
      },
      {
        "id": "535e8cbd-c8aa-42c3-99d8-034e5fe739c7",
        "tag": "markdown",
        "content": "## They're Alive\n\nWhat are the signs by which we observe that a corporate entity lives? Clearly, a corporate entity cannot directly produce force to move objects in the real world. But this certainly is a bias caused by the heuristic we have for judging what a living entity looks like. We see plants grow and animals interact with their environment and conclude that they are alive because of their effect on the environment. So why then is a corporation not alive if it can move entire shipping containers of goods half way across the world? You might argue that it can't 'decide' anything because humans make decisions. This is wrong in my mind for at least two reasons. Firstly, by that argument a computer can't compute anything because it is specifically the changing patterns of voltages across the semiconductor substrate that results in the 'computation'. This is technically true, but pointlessly pedantic. Analogously, while humans still make most of the decisions in corporations, it's increasingly obvious that corporations use a heterogenous decision making structure in which human beings are only one, arguably diminishing part. This is made incredibly clear when one part of that [decision process catastrophically fails](https://en.wikipedia.org/wiki/2022_Southwest_Airlines_scheduling_crisis), crippling the organisations ability to think and function. The second reason that it is wrong is that even when the decision making is purely human there are numerous theories about the 'collective mind' that is created by a collection of human minds spawning terms such as 'zeitgeist', 'egregore' and 'intersubjective reality'. I think a common misconception is the believing that the consensus opinion would fall somewhere within the '[convex hull](https://en.wikipedia.org/wiki/Convex_hull)' formed by its constituent opinions as would be put forward by an idea such as the '[Overton Window](https://en.wikipedia.org/wiki/Overton_window)', but I don't think it's necessarily that hard contrive an example of when this is not the case. Even allowing for many instances of sadism and aggrandisement, it's hard for me to believe that somewhere in time there isn't one case where a high-priest genuinely disliked the prospect of sacrificing a village child to the rain gods, and so not a single person could be found who liked the idea, but, collectively, all feel compelled to agree that the undesirable action must be taken. An instance of something exactly like this can certainly [be found in Greek mythology](https://en.wikipedia.org/wiki/Iphigenia). It can be argued that most of what a corporation 'wants' can be distilled eventually down to what the owners of a corporation wants, and anything else a corporation does is a manifestation of the principal-agent problem. However, I think the survival of the fittest environment created by corporate competition, combined with the 'winner take all' dynamics of many of the most important modern sections has detached the true desire of a corporation: namely, growing its resource pool, from the clearer directive to return money to shareholders. It is in light of this that ideas such as blitzscaling and perpetual 100% reinvestment of profits make more sense."
      },
      {
        "id": "cafe46cb-6e4a-44f1-b9c4-09b31b0d9b7e",
        "tag": "markdown",
        "content": "## They're Superintelligent\n\nLoss of control scenarios in AI typically focus on how a superintelligent entity develops agency and then begins to start pursuing goals that are divergent from its makers. Having already made the argument that corporations have the ability to pursue goals divergent from any and all groups of stakeholders, we should also consider the argument that companies are 'superintelligent'. When you consider the complexities required in setting up and maintaining [the supply chain required to deliver millions of iPhones](https://www.aei.org/research-products/report/apples-supply-chain-economic-and-geopolitical-implications/) into hands of consumers half way across the world from where they're assembled while navigating myriad rules and regulations of two completely different societal paradigms this seems nothing short of superhumanly intelligent — where we can explicitly take intelligence to mean the ability to achieve some desired outcome. Much of the credit for the success of a company is typically laid at the feet of the man or woman in charge. And indeed, much has been written on the [supply chain mastery of Tim Cook](https://supplychaindigital.com/technology/tim-cook-supply-chain-guru-behind-apple-growth). Now Tim Cook is for sure a very bright guy, with decades of experience in the area of this sort of logistical legerdemain, but can you actually just imagine him sitting there taking every single decision that needs to be made? Replying to every single supplier email? Handling every single small fire? The person at the top sets a vibe and creates a culture, but the genius of a corporation emerges from the gestalt of the decisions made by the problem solvers (human or otherwise) it uses as the thinking substrate for achieving its ends. Much like the earlier point that corporations are alive, that they represent an intelligence greater than any individual may seem contrived, but if the conjecture that a corporation can represent viewpoints that are distinct from all of its human stakeholders is correct, it is clear you can expect there to be an alignment problem."
      },
      {
        "id": "58ed49aa-ccbf-4a81-ab63-be2a6a056ed6",
        "tag": "markdown",
        "content": "## All of Us, Combined\n\nLet's ascend another level here and consider the superstructure of ALL corporations. Just as an 'individual' corporation has desires and acts accordingly, so too can we consider the species of Corpus Capitalus to act on, and transform its environment. This occurs in a way not too dissimilar from the way that individuals with no familial relationship — and are therefore typically in competition with one another — may engage in collective [mobbing](https://en.wikipedia.org/wiki/Mobbing_(animal_behavior)) behaviour to harass members of a rival species. Just as many micro-organisms modify their environment to reduce inter-species competition so too can corporations modify their environment and co-operate when the need arises. This idea makes behaviour that is [hard to understand](https://www.bloomberg.com/news/articles/2024-05-01/google-s-payments-to-apple-reached-20-billion-in-2022-cue-says) through the purely competitive rubric much less surprising. The 'corpus' of all corporations can all agree on a few things: for example, they value political stability and low corporate taxes. Just as nature abhors a vacuum, endeavouring to fill it if possible, so too do corporations abhor chaotic policy environments and so they will modify their environment to diminish it if they. Perhaps one of the clearest examples of this modification is [Citizen's United](https://en.wikipedia.org/wiki/Citizens_United_v._FEC) which enshrines the right a corporation to express its desires on a level equal to any other 'person'. This provides a clear and easy mechanism for corporations to directly influence their environment."
      },
      {
        "id": "657119e1-d19d-456c-8a39-f2e09690f123",
        "tag": "markdown",
        "content": "## Humanity's Last Hope\n\nI don't think the correct conclusion is that corporations are 'evil' for the same reason that I don't think a crocodile is evil for ambushing an unsuspecting person on the shoreline. Corporations have 'evolved' in a similar sense to animals in the wild. The selection pressure for efficient use of capital has refined the artificial organism that is a for-profit company into something that makes efficient use of capital. A corporation 'cares' for the individuals it employs about as much as one might care for one's liver: the general health of an organs is something an individual may care about, but the individual turnover of cells is beyond scope of concern. People care for their 'brain' in so far as the healthy functioning of it makes a qualitative difference to their lives, but many people do not let a little bit of brain damage get in the way of having a good time in the short term. Corporations are creatures, pseudo-organisms bred for a world we humans originally designed. And we should expect them to evolve for the selection pressures they encounter and modify their environment like any other species. We should also recognise the paradox of expecting something narrowly optimised for one objective function to somehow develop robust capabilities it wasn't refined for. Finally, we should appreciate the lessons all these observations suggest about the parallels between [repeated attempts](https://en.wikipedia.org/wiki/Environmental,_social,_and_governance) to ['patch' corporations](https://en.wikipedia.org/wiki/Benefit_corporation) and our current safeguards based approach to mitigating AI risks which is certainly necessary but not at all sufficient. No individual (human or corporate) can change the entire ecosystem — even the most well resourced individuals cannot unilaterally [hold back](https://en.wikipedia.org/wiki/Open_letter_on_artificial_intelligence) [the tide](https://www.youtube.com/shorts/zEc0H-U6RNA) development or resist the fundamental dynamics of the competitive ecosystem. Perhaps I am too much of a typical liberal in that I am too quick to blame the systemic factors and too lenient on the individual, but I strongly believe that our only hope against the increasingly confluent dynamics of superintelligent corporations and the superintelligent AI they will inevitably birth is to empower governmental organisations (in the broadest sense) if only as a counterweight. For nature teaches us that all equilibria are dynamic and the only universal rules are competition and survival of the fittest. {I think I need to flesh this last section out more}"
      }
    ],
    "tags": ["alignment", "society"]
  }
]
